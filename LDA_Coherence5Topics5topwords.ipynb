{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915ccc0-a499-4259-87f3-a9056eb07b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "(5 topics, 10 terms, top 10 words for each topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62ed93e3-3100-4f1c-9fdc-35678c44b3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pascal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pascal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: oxford, university, one, city, day\n",
      "Topic 2: tour, oxford, university, walking, guide\n",
      "Topic 3: see, university, visit, harry, potter\n",
      "Topic 4: colleges, place, college, visitors, amazing\n",
      "Topic 5: oxford, university, colleges, buildings, visit\n",
      "Topic 1 Coherence Score: 5.63719159358808\n",
      "Topic 2 Coherence Score: 5.388683344093934\n",
      "Topic 3 Coherence Score: 4.9475448521904655\n",
      "Topic 4 Coherence Score: 4.076473294769559\n",
      "Topic 5 Coherence Score: 6.113906365989224\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([word for word in tokens if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Load Dataset\n",
    "# Replace 'university_of_oxford_tripadvisor_reviews.csv' with your file path if necessary\n",
    "df = pd.read_csv(\"university_of_oxford_tripadvisor_reviews.csv\")\n",
    "\n",
    "# Preprocess Text\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Create Bag of Words Representation\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(df['cleaned_text'])\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Fit LDA Model\n",
    "n_topics = 5  # Number of topics\n",
    "lda_model = LatentDirichletAllocation(n_components=n_topics, random_state=200)\n",
    "lda_model.fit(bow_matrix)\n",
    "\n",
    "# Extract Topics\n",
    "def extract_topics(lda_model, feature_names, n_top_words=5):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        topics.append(top_words)\n",
    "        print(f\"Topic {topic_idx + 1}: {', '.join(top_words)}\")\n",
    "    return topics\n",
    "\n",
    "topics = extract_topics(lda_model, vocab, n_top_words=5)\n",
    "\n",
    "# Coherence Score Calculation\n",
    "def compute_coherence_score(topics, bow_matrix, vocab):\n",
    "    # Compute co-occurrence matrix\n",
    "    co_occurrence_matrix = np.dot(bow_matrix.T, bow_matrix)\n",
    "    vocab_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    \n",
    "    def topic_coherence(topic):\n",
    "        coherence = 0\n",
    "        n_pairs = 0\n",
    "        for word1, word2 in combinations(topic, 2):\n",
    "            idx1, idx2 = vocab_to_idx[word1], vocab_to_idx[word2]\n",
    "            co_occurrence = co_occurrence_matrix[idx1, idx2]\n",
    "            if co_occurrence > 0:\n",
    "                coherence += np.log(co_occurrence + 1)  # +1 to avoid log(0)\n",
    "                n_pairs += 1\n",
    "        return coherence / n_pairs if n_pairs > 0 else 0\n",
    "    \n",
    "    return [topic_coherence(topic) for topic in topics]\n",
    "\n",
    "# Compute and Print Coherence Scores\n",
    "coherence_scores = compute_coherence_score(topics, bow_matrix, vocab)\n",
    "for idx, score in enumerate(coherence_scores):\n",
    "    print(f\"Topic {idx + 1} Coherence Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66282c5-2a00-4174-a186-a002a35b10ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4681286f-e078-4587-a7d4-d81bfee81f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pascal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pascal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: oxford, university, colleges, college, visit, one, buildings, see, tour, many\n",
      "Topic 2: oxford, university, city, cambridge, english, universities, students, town, world, teaching\n",
      "Topic 3: college, university, colleges, church, merton, street, world, one, oldest, christ\n",
      "Topic 4: oxford, tour, college, day, city, london, walking, train, trip, street\n",
      "Topic 5: colleges, city, around, visitors, open, visit, walk, see, well, several\n",
      "LSA (BoW) - Topic 1 Coherence Score: 5.578871626033516\n",
      "LSA (BoW) - Topic 2 Coherence Score: 3.624961595470655\n",
      "LSA (BoW) - Topic 3 Coherence Score: 4.640133441489119\n",
      "LSA (BoW) - Topic 4 Coherence Score: 4.103232093165759\n",
      "LSA (BoW) - Topic 5 Coherence Score: 4.22909551398272\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([word for word in tokens if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv(\"university_of_oxford_tripadvisor_reviews.csv\")\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "# Function to Extract Topics\n",
    "def extract_topics(model, vectorizer, n_top_words=10):\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "    topics = []\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        top_words = [vocab[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        topics.append(top_words)\n",
    "        print(f\"Topic {idx + 1}: {', '.join(top_words)}\")\n",
    "    return topics\n",
    "\n",
    "# Function to Calculate Coherence Scores\n",
    "def compute_coherence_score(topics, matrix, vocab):\n",
    "    # Compute co-occurrence matrix\n",
    "    co_occurrence_matrix = np.dot(matrix.T, matrix)\n",
    "    vocab_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    \n",
    "    def topic_coherence(topic):\n",
    "        coherence = 0\n",
    "        n_pairs = 0\n",
    "        for word1, word2 in combinations(topic, 2):\n",
    "            idx1, idx2 = vocab_to_idx[word1], vocab_to_idx[word2]\n",
    "            co_occurrence = co_occurrence_matrix[idx1, idx2]\n",
    "            if co_occurrence > 0:\n",
    "                coherence += np.log(co_occurrence + 1)  # +1 to avoid log(0)\n",
    "                n_pairs += 1\n",
    "        return coherence / n_pairs if n_pairs > 0 else 0\n",
    "    \n",
    "    return [topic_coherence(topic) for topic in topics]\n",
    "\n",
    "# Bag of Words\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow_matrix = bow_vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# LSA with BoW\n",
    "lsa_bow_model = TruncatedSVD(n_components=5, random_state=42)\n",
    "lsa_bow_model.fit(bow_matrix)\n",
    "\n",
    "# Extract Topics\n",
    "lsa_bow_topics = extract_topics(lsa_bow_model, bow_vectorizer)\n",
    "\n",
    "# Compute Coherence\n",
    "lsa_bow_coherence = compute_coherence_score(lsa_bow_topics, bow_matrix.toarray(), bow_vectorizer.get_feature_names_out())\n",
    "for idx, score in enumerate(lsa_bow_coherence):\n",
    "    print(f\"LSA (BoW) - Topic {idx + 1} Coherence Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32504e55-722f-4364-8deb-eab2931cb03e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
